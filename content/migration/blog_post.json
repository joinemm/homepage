[
  {
    "status": "published",
    "slug": "yubikey-nixos-guide",
    "date_created": "2024-07-02",
    "title": "Getting the most out of your Yubikey on NixOS",
    "tags": ["nix", "security"],
    "excerpt": "There are many different use cases I found for the Yubikeys.",
    "content": "I recently got myself two [Yubikey 5](https://www.yubico.com/us/product/yubikey-5-series/yubikey-5-nfc/) devices. One of them will live on my keychain, while the second one is a backup that doesn't leave my house.\n\nFirefox works out of the box with the Yubikeys and I can add them to various accounts. In addition to using them as 2fa through the browser, I wanted to use them on the OS level as well.\n\nFor in-depth details on all of the functionality of the Yubikey, refer to this excellent Reddit post: [\"What the heck is a Yubikey and why did I buy one?\": A user guide](https://www.reddit.com/r/Yubikey/comments/n8wr55/what_the_heck_is_a_Yubikey_and_why_did_i_buy_one/)\n\n## Use cases\n\nThere are many different use cases I found for the Yubikeys. I have marked the ones I have succesfully gotten working. Note that I don't necessarily want or endorse the ones I have left undone.\n\n- `pam` auth (sudo/login) ✅\n- 2fa for websites (works out of the box) ✅\n- GPG keys ✅\n- SSH keys ❓\n- Git commit signing ✅\n- Yubikey based full disk encryption ([guide](https://nixos.wiki/wiki/Yubikey_based_Full_Disk_Encryption_(FDE)_on_NixOS)) ❓\n- sops secret encryption (waiting for [PR](https://github.com/getsops/sops/pull/1465)) ❌\n\n## Pam module\n\nThere are two pam modules that implement Yubikey functionality: `yubico-pam` and `pam_u2f`, the latter of which seems to be the more modern and recommended approach. I did try `yubico-pam` but I was unable to get it working.\n\n> The `pam_u2f` module implements the U2F (universal second factor) protocol. The protocol was initially developed by Yubico, Google and NXP and is nowadays hosted as an open-standard by the FIDO Alliance. All current and most legacy Yubikeys support the U2F protocol making this the preferred way to use Yubikeys for user login.\n\nI ended up using the `pam_u2f` module. This allows the Yubikey to work as a replacement for sudo/login password. The configuration is also completely declarative and I'm able to enroll my Yubikeys, including the backup key, to another device without actually having all of the keys with me. How is this possible?\n\n1. Connect your Yubikey.\n2. Create authorization mappings for your keys. This file works similarly to `ssh/known_hosts` and is not a secret.\n\n```\nnix-shell -p pam_u2f\npamu2fcfg -n -o pam://yubi\n```\n\n3. The command above will look like it just hangs. You have to touch your Yubikey to continue. You will get a public key for your Yubikey printed into the terminal. This key will be different every time you run the command. Save it somewhere, you will need it later.\n4. Repeat steps 1-3 for your other Yubikeys.\n\nEnable `u2f` in your nixos configuration:\n\n```nix\nsecurity.pam.u2f = {\n  enable = true;\n  interactive = true;\n  cue = true;\n};\n```\n\n- `interactive`: will prompt you with `Insert your U2F device, then press ENTER.`\n- `cue`: will print `Please touch the device.` when your action is required.\n\n### Hardening\n\nThe guides for `pam_u2f` tell you to save the key mappings in `~/.config/u2f_keys`. I would advice you don't do that as I find it a security risk. Somehow I didn't find anyone talking about this flaw online:\n\nSay a bad actor has physical access to your machine (ok this is already a pretty bad situation but it gets worse). They could plug in their Yubikey, run the above commands, and append their keys to your mapping file. Doing so would give them instant escalation to sudo privileges *without knowing your password*. Sounds pretty bad doesn't it!\n\nHow to mitigate this? Don't store the key mappings in user writable location. A better place is `/etc/u2f-mapping`. My configuration creates a file in the read-only `/nix/store`.\n\n### Sharing\n\nIf you run `pamu2fcfg` with the default arguments, the origin will be `pam://$HOSTNAME`. This means the keys will only work on that specific machine (or any other with the same hostname) - not what we want - this is why I have chosen a more global origin: `pam://yubi`. It can be anything you want.\n\nNow that the keys are usable anywhere, they can be embedded into the nixos configuration:\n\n```nix\nsecurity.pam.u2f = {\n  origin = \"pam://yubi\";\n  authFile = pkgs.writeText \"u2f-mappings\" (lib.concatStrings [\n    username\n    \":<KeyHandle1>,<UserKey1>,<CoseType1>,<Options1>\"\n    \":<KeyHandle2>,<UserKey2>,<CoseType2>,<Options2>\"\n  ]);\n};\n```\n\nI am using the `lib.concatStrings` function to split the keys onto multiple lines, and insert my username (a string value imported from elsewhere) to the beginning of the line. This is only to make it more readable and can be omitted.\n\n### Enable for sudo and login\n\nThere is only one thing left to do, enable the U2F module for any services you wish. I have enabled it for sudo and login:\n\n```nix\nsecurity.pam.services = {\n  login.u2fAuth = true;\n  sudo.u2fAuth = true;\n};\n```\n\n## GPG keypair\n\nAdd the following to your nixos system configuration:\n\n```nix\nservices = {\n  pcscd.enable = true;\n  udev.packages = [ pkgs.yubikey-personalization ];\n};\n```\n\nAnd the following to your `home-manager` configuration. Most of this is not actually required but they are good hardening steps (apparently...).\n\n`disable-ccid` is crucial to prevent pcscd daemon and gpg-agent conflicts.\n\n```nix\nprograms.gpg = {\n  enable = true;\n\n  # https://support.yubico.com/hc/en-us/articles/4819584884124-Resolving-GPG-s-CCID-conflicts\n  scdaemonSettings = {\n    disable-ccid = true;\n  };\n\n  # https://github.com/drduh/config/blob/master/gpg.conf\n  settings = {\n    personal-cipher-preferences = \"AES256 AES192 AES\";\n    personal-digest-preferences = \"SHA512 SHA384 SHA256\";\n    personal-compress-preferences = \"ZLIB BZIP2 ZIP Uncompressed\";\n    default-preference-list = \"SHA512 SHA384 SHA256 AES256 AES192 AES ZLIB BZIP2 ZIP Uncompressed\";\n    cert-digest-algo = \"SHA512\";\n    s2k-digest-algo = \"SHA512\";\n    s2k-cipher-algo = \"AES256\";\n    charset = \"utf-8\";\n    fixed-list-mode = true;\n    no-comments = true;\n    no-emit-version = true;\n    keyid-format = \"0xlong\";\n    list-options = \"show-uid-validity\";\n    verify-options = \"show-uid-validity\";\n    with-fingerprint = true;\n    require-cross-certification = true;\n    no-symkey-cache = true;\n    use-agent = true;\n    throw-keyids = true;\n  };\n};\n\nservices.gpg-agent = {\n  enable = true;\n\n  # https://github.com/drduh/config/blob/master/gpg-agent.conf\n  defaultCacheTtl = 60;\n  maxCacheTtl = 120;\n  pinentryPackage = pkgs.pinentry-curses;\n  extraConfig = ''\n    ttyname $GPG_TTY\n  '';\n};\n```\n\nFollow this [guide](https://github.com/drduh/YubiKey-Guide) to create a GPG master key, with 3 different subkeys: signing key, encryption key and authentication key. After generating the keys, back them up on a USB stick. Once you have backups, move the keys over to the Yubikey. This is all explained in great detail in the aforementioned guide.\n\nYou can create a shell with all the packages you need to follow the guide (assuming you already deployed the configuration above):\n```sh\nnix-shell -p yubikey-manager cryptsetup\n```\n\nIf you added the public key URL onto the Yubikey, on any computer you plug the key in, you can now fetch the public key like this:\n```sh\ngpg --edit-card\ngpg/card> fetch\ngpg/card> quit\n\ngpg --edit-key $KEYID\ngpg> trust\nYour decision? 5\nDo you really want to set this key to ultimate trust? (y/N) y\ngpg> quit\n```\n\nThe Yubikey can now be used as your GPG keypair!\n\n## Git commit signing\n\nConfigure git to use your newly created GPG key to sign commits. Using home-manager:\n\n```nix\nprograms.git = {\n  userEmail = \"same as your key identity\"\n  signing.key = \"$KEYID\";\n  extraConfig.commit.gpgsign = true;\n};\n```\n\nNow whenever you `git commit` it will sign with your Yubikey, asking for the pin for the first signing after boot.\n\n## Sources\n\n[https://nixos.wiki/wiki/Yubikey](https://nixos.wiki/wiki/Yubikey)\n\n[https://developers.yubico.com/pam-u2f](https://developers.yubico.com/pam-u2f)\n\n[https://github.com/drduh/YubiKey-Guide](https://github.com/drduh/YubiKey-Guide)\n",
    "image": {
      "filename_disk": "f40f7e96-9c28-4b38-8d53-7c480017c56b.jpg",
      "filename_download": "Rippling_Blog_Hero_ITSeries__Yubikey-scaled.jpg"
    }
  },
  {
    "status": "published",
    "slug": "next-gen-discord-bot-idea",
    "date_created": "2024-03-23",
    "title": "Next-gen Discord bot architecture idea",
    "tags": ["discord-bot", "programming"],
    "excerpt": null,
    "content": "*I wrote this during my 3 hour flight to Italy as I was really bored. It describes a hypothetical overengineered microservices based system for Miso Bot, my discord bot.*\n\n## Gateway\n\nWe start with a **gateway service** that connects to the discord api. this service would handle any interaction with the discord api gateway and keep the shards open.\n\nThis service acts as a proxy for the real discord gateway, and as such would need to be drop-in compatible. The clients connecting to this service would think it is the real discord gateway.\n\nFrom this service, the discord gateway events will enter a queue such as rabbitmq. The **queue service** filters and sorts the events, before dispatching them further for handler services. \n\nThis queue will integrate with the gateway, so clients will not need to know of it's existence. It will also work both ways, for incoming and outgoing events. The discord ratelimits are also respected, and events will remain enqueued until the rate limit allows them through. The goal is to have 0% dropped event rate. If there are no handlers available, the items remain queued until one appears online.\n\n## Handlers\n\nThe **handler services** will connect to the gateway proxy as if it was the regular discord API. These clients can as such use any discord library implementation, as long as the URL can be configured.\n\n### Event handler service\nSubscribes to various discord events such as member joins and leaves, new guilds, reactions etc., and act accordingly.\n\n### Message handler service\nSubscribes to new message events to read their content. Based on the content, the messages can be redirected further to the **Command handler** or processed for passive events such as notifications or activity calculation.\n\n### Command handler service\nWill take in events where a command prefix has been detected. The arguments are parsed, and a request is sent to the internal **Command action API** if the syntax matches a valid command. Since commands are just messages, this handler will not subscribe to any discord events, but instead take in forwarded message events from the message handler. The response is formatted for discord and sent to the user. Not all commands need the action API, if their entire functionality is to display discord data in a pretty embed.\n\n## APIs\n\nREST API services running in the backend.\n### Commands API\nThis is a REST service that executes commands. It takes in the command's arguments and any relevant context as JSON, and returns the response in another JSON. This service will not be connected to the discord API, and functions as it's own separate unit, being platform agnostic. This allows command usage from various clients, such as web browsers or other chat apps, without changing the core command functionality. The client's job is only to format the result. This should be the only service that has access to the database.\n\n### Data API\n\nThis is a small REST service to facilitate querying discord data from the gateway proxy, as well as the discord OAuth API. It will provide data relating to the logged in user, such as their guilds, and channels in those guilds.\n\nThe data API has an active gateway connection, and maintains the in-memory cache of users and guilds members.\n\n## Web control panel\n\nThis should be the main way for users to change the settings for themselves or their guild. The web panel will interact with the **Commands API** to change database fields as user selects them from a drop-down. The drop-downs will be populated using the **Data API** after user has logged in.\n\n## Scaling\n\nThe gateway queue will act as a load-balancing service, dispatching events to handlers based on their load. The handlers - as well as the commands API - can be horizontally scaled and duplicated as they have no state.\n\n## Command specific APIs\n\nThese services solve a problem specific to the commands implemented, and will be used by the commands API.\n\n### Lastfm middleware\n\nThe purpose of this middleware API is to provide easier and less error-prone access to the real Lastfm API. It will also use web-scraping to augment and enhance the data received, and implement caching for frequently used routes and rarely changing data.\n\n### Media embedder\n\nThis API would separate media scraping and retrieving of data from social media services into one unified schema.",
    "image": {
      "filename_disk": "ea7e75dd-72cb-4a78-9eaf-5c72915f4f95.jpg",
      "filename_download": "PXL_20240323_121435557~2.jpg"
    }
  },
  {
    "status": "published",
    "slug": "development-environments-with-nix",
    "date_created": "2024-01-23",
    "title": "Easy development environments with Nix shells",
    "tags": ["devops", "nix", "python"],
    "excerpt": "Say goodbye to installing every package on the system level",
    "content": "I work on a lot of projects, on many computers. Trying to keep all the software I need on all of them (and on a consistent version) has proved to be a challenging task. Sure virtualenvs or docker containers solve this partially, when you expect some cli tool to be there and it's not, that can really break your flow.\n\n## Devenv\n\nMeet [devenv](https://devenv.sh/).\n\n> Fast, Declarative, Reproducible, and Composable Developer Environments using Nix\n\nNot only does this solve my problem, it also feeds my recent obsession with Nix :D\n\nDevenv can be set up a couple of ways, but I immediately jumped into [flakes](https://devenv.sh/guides/using-with-flakes/) as I've been writing a lot of flakes for my [NixOS configuration](http://git.joinemm.dev/snowflake).\n\nHere is the `flake.nix` boilerplate to use devenv. Simply copy this into the root of your project and start adding configuration:\n\n```nix\n{\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-23.11\";\n    devenv.url = \"github:cachix/devenv\";\n  };\n\n  nixConfig = {\n    extra-trusted-public-keys = \"devenv.cachix.org-1:w1cLUi8dv3hnoSPGAuibQv+f9TZLr6cv/Hm9XgU50cw=\";\n    extra-substituters = \"https://devenv.cachix.org\";\n  };\n\n  outputs = {\n    nixpkgs,\n    devenv,\n    ...\n  } @ inputs: let\n    pkgs = nixpkgs.legacyPackages.\"x86_64-linux\";\n  in {\n    devShell.x86_64-linux = devenv.lib.mkShell {\n      inherit inputs pkgs;\n      modules = [\n        ({\n          pkgs,\n          lib,\n          ...\n        }: {\n       \t  # devenv configuration goes here\n        })\n      ];\n    };\n  };\n}\n```\n\n## Configuration\n\nSo what can you configure then?\n\n### Languages\n\nEnabling the python interpreter and installing poetry for dependency management.\n\n```nix\n... }: {\n  languages.python = {\n    enable = true;\n    poetry.enable = true;\n  };\n}\n```\n\n### Packages\n\nInstalling packages from nixpkgs, like ffmpeg and python linting/formatting tools.\n\n```nix\n... }: {\n  packages = with pkgs; [\n    ffmpeg\n    isort\n    black\n    ruff\n    reuse\n  ];\n}\n```\n\n### Scripts / Aliases\n\nYou can even write custom shell scripts to be added to the environment. This is useful to avoid typing out long commands you use often (poetry...).\n\n```nix\n... }: {\n  scripts.\"run\".exec = ''\n    poetry run python main.py $1\n  '';\n}\n```\n\nThis way I can easily run `main.py foo` by just typing `run foo`.\n\n### Pre-commit hooks\n\nTake away the pain of managing pre-commit hooks and let nix do it for you. This option has one pretty big flaw though: It overwrites your manually written `.pre-commit-config.yml` with a symlink to the nix store. This means you will not be able to use hooks written by your non-enlightened (not using nix) coworkers, nor share this one with them. The files will be in conflict. **You have been warned**.\n\nFor personal projects it's nice though.\n\n```nix\n... }: {\n  pre-commit.hooks = {\n    isort.enable = true;\n    black.enable = true;\n    ruff = {\n      enable = true;\n      entry = lib.mkForce \"${pkgs.ruff}/bin/ruff --fix --ignore=E501\";\n    };\n  };\n}\n```\n\nHere I am adding `isort`, `black` and `ruff` as pre-commit hooks for my project, and adding extra args for ruff to ignore `E501` (line too long) errors.\n\n> Note that these tools do *not* have to be installed separately as packages to use them in pre-commit hook. I am just doing it so I can run them manually.\n\n### Bringing it together\n\nHere is my current `flake.nix` for [Miso Bot](https://git.joinemm.dev/miso-bot)\n\n```nix\n{\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-23.11\";\n    devenv.url = \"github:cachix/devenv\";\n  };\n\n  nixConfig = {\n    extra-trusted-public-keys = \"devenv.cachix.org-1:w1cLUi8dv3hnoSPGAuibQv+f9TZLr6cv/Hm9XgU50cw=\";\n    extra-substituters = \"https://devenv.cachix.org\";\n  };\n\n  outputs = {\n    nixpkgs,\n    devenv,\n    ...\n  } @ inputs: let\n    pkgs = nixpkgs.legacyPackages.\"x86_64-linux\";\n  in {\n    devShell.x86_64-linux = devenv.lib.mkShell {\n      inherit inputs pkgs;\n      modules = [\n        ({\n          pkgs,\n          lib,\n          ...\n        }: {\n          dotenv.disableHint = true;\n\n          packages = with pkgs; [\n            ffmpeg\n            isort\n            black\n            ruff\n            reuse\n          ];\n\n          pre-commit.hooks = {\n            isort.enable = true;\n            black.enable = true;\n            ruff = {\n              enable = true;\n              entry = lib.mkForce \"${pkgs.ruff}/bin/ruff --fix --ignore=E501\";\n            };\n          };\n\n          languages.python = {\n            enable = true;\n            poetry.enable = true;\n          };\n\n          scripts.\"run\".exec = ''\n            poetry run python main.py $1\n          '';\n        })\n      ];\n    };\n  };\n}\n```\n\n## Usage\n\nNow that we have this environment configured in `flake.nix`, how do we use it? \n\nSimply run:\n\n```sh\nnix develop --impure\n```\n\nThe building of the nix packages will take some time but eventually you will be dropped in a bash shell containing the environment you specified. If you're a zsh (or some other shell) user like me, you might be wondering; Do I really have to use bash now? Don't worry. There is a fix for that:\n\n```sh\n# exit the bash shell you're now in\nexit\n\n# relaunch the devshell with your own shell\nnix develop --impure -c $SHELL\n```\n\nNow you have the same shell but it's using zsh and keeps all your zsh config/aliases. Speaking of aliases, I have made this alias to greatly simplify the change into a devshell:\n\n```sh\nalias dev=\"nix develop --impure -c $SHELL\"\n```\n\nAllowing me to simply write \"dev\" once I'm in my project folder.\n\n> It is possible to use `direnv` and `.envrc` to change into the devshell automatically, but I tried that and did not like it. I don't *always* need the devshell if I'm simply browsing files and it's easy enough to do manually.\n\n## Caching\n\nIf you are using nix garbage collection, then the devshell derivations are deleted by the nix garbage collector. This can be annoying, as you will have to rebuild your environment all the time. To remedy this, add this to your nix configuration:\n\n```nix\nnix.extraOptions = ''\n  keep-outputs = true\n  keep-derivations = true\n'';\n```\n\n",
    "image": {
      "filename_disk": "5235c9f8-7d0d-405e-bf34-2f7de18b9a82.jpg",
      "filename_download": "beautiful-shell-digital-art-illustration_442940-8208.jpg"
    }
  },
  {
    "status": "published",
    "slug": "prometheus-ssh-proxy-nixos",
    "date_created": "2023-12-12",
    "title": "Scraping prometheus metrics through SSH with NixOS",
    "tags": ["devops", "nix", "prometheus"],
    "excerpt": "Stop opening your ports to the whole world",
    "content": "The other day I was setting up a Grafana + Prometheus monitoring stack for a client, and everything was going well. I was scraping metrics from various servers with https, protected behind http basic auth (thanks to nginx), until a security audit decided we do not want to open ports 80 or 443 to the world. In fact we don't want to run a web server at all on these servers. So how to get metrics without http access?\n\n## Metrics through ssh?\n\nThere are multiple solutions to this problem, one of which would have been firewall setting allowing only connections from our monitoring server. This would still require us to have a running web server though, and keep the firewalls up to date. Then it occurred to me; could the metrics be scraped through ssh? I had not considered this approach but it would solve all our problems. The servers are already accessed with ssh by every other service we run. This required further investigation.\n\nUnfortunately - after reading countless of docs - I found out prometheus does not support scraping metrics through ssh. At this point I was ready to scrap the whole idea, but then I found [sshified](https://github.com/hoffie/sshified).\n\n> sshified acts as an HTTP proxy and forwards all received requests over server-specific SSH connections.\n\nWait, this sounds perfect for our use case!\n\n<Aside>\nWhy not just use `ssh -L`? Because the ssh tunnel would have to be kept open indefinitely, which is not very reliable. `sshified` on the other hand opens a new ssh connection for each request.\n</Aside>\n\n## Trying out sshified\n\nI got myself a copy of `sshified` and set up a little test.\n\n> IP address `1.2.3.4` here refers to the remote server which does not have any ports open aside from port 22\n\nOn the remote server we have `node-exporter` running on port `9100`, and ssh keys set up so I can login with my user.\n\nFirst we try to query the metrics without a proxy:\n\n```sh\n$ curl 1.2.3.4:9100/metrics --connect-timeout 5\n\ncurl: (28) Failed to connect to 1.2.3.4 port 9100 after 5002 ms: Timeout was reached\n```\n\nThe request times out, as expected. It's hitting the firewall. Now lets spin up the proxy on port `8888`.\n\n```sh\n./sshified --proxy.listen-addr 127.0.0.1:8888 \\\n  --ssh.user joinemm \\\n  --ssh.key-file ~/.ssh/id_ed25519 \\\n  --ssh.known-hosts-file ~/.ssh/known_hosts \\\n  --ssh.port 22 -v\n```\n\nAnd request the metrics through that proxy:\n\n```sh\ncurl --proxy 127.0.0.1:8888 1.2.3.4:9100/metrics\n```\n\nThe terminal fills with `node-exporter` metrics. It's working! Now we just have to recreate this in nix configuration.\n\n## The nix way\n\nIf these were traditional ubuntu servers we would just set these things up manually and be done with it, but we are using NixOS and flakes. Everything must be reproducable.\n\nUnfortunately, `sshified` is not included in [nixpkgs](https://github.com/NixOS/nixpkgs), so installing it is not so straightforward. I had to write my own derivation to build the thing. Thankfully it's just a go module so it's relatively easy to build.\n\n`./pkgs/sshified/default.nix`\n```nix\n{\n  lib,\n  buildGoModule,\n  fetchFromGitHub,\n}:\nbuildGoModule rec {\n  pname = \"sshified\";\n  version = \"1.1.15\";\n\n  src = fetchFromGitHub {\n    owner = \"hoffie\";\n    repo = pname;\n    rev = \"v${version}\";\n    sha256 = \"sha256-zbgwCWs+DNJ1ZmAl9h0PuJvLO3yMhE/t6T1aqpwYOgk=\";\n  };\n\n  vendorHash = null;\n\n  ldflags = [\n    \"-s\"\n    \"-w\"\n    \"-X main.Version=${version}\"\n  ];\n\n  subPackages = [\".\"];\n\n  meta = with lib; {\n    description = \"Acts as an HTTP proxy and forwards all received requests over server-specific SSH connections \";\n    homepage = \"https://github.com/hoffie/sshified\";\n    license = licenses.mit;\n    maintainers = with maintainers; [joinemm];\n    mainProgram = \"sshified\";\n  };\n}\n```\n\nI should make a PR to nixpkgs to get this merged but for now it's easily imported from a file in our configuration:\n\n```nix\n{ ... }: let\n  sshified = pkgs.callPackage ../../pkgs/sshified/default.nix {};\nin {\n...\n  environment.systemPackages = [\n    sshified\n  ];\n...\n```\n\nAfter building this configuration, `sshified` is now available in our `$PATH`. But we don't want to launch it manually of course. That's where this systemd service comes in.\n\n```nix\nusers.users.\"sshified\" = {\n  isNormalUser = true;\n};\n\nsystemd.services.\"sshified\" = {\n  wantedBy = [\"multi-user.target\"];\n  after = [\"network.target\"];\n  description = \"Run the sshified http-to-ssh proxy\";\n  serviceConfig = {\n    User = \"sshified\";\n    ExecStart = ''\n      ${sshified}/bin/sshified \\\n      --proxy.listen-addr 127.0.0.1:8888 \\\n      --ssh.user sshified \\\n      --ssh.key-file ${config.sops.secrets.sshified_private_key.path} \\\n      --ssh.known-hosts-file /etc/ssh/ssh_known_hosts \\\n      --ssh.port 22 \\\n      -v\n    '';\n  };\n};\n```\n\nThe service is run automatically and makes `sshified` available on port `8888`. You might be wondering where those ssh settings come from, but we'll get there.\n\nNow.\n\n## SSH configuration\n\nThe ssh keys need to be set up somehow without manual intervention, and they cannot be leaked to public. For this we use [sops-nix](https://github.com/Mic92/sops-nix). I will not go into usage of sops in this blog post but you can read the docs.\n\n```nix\n# this will make the private key readable by our sshified user\nsops.secrets.sshified_private_key.owner = \"sshified\";\n\n# this will create /etc/ssh/ssh_known_hosts\nservices.openssh.knownHosts = {\n    \"[1.2.3.4]:22\".publicKey = \"ssh-ed25519 XXX\";\n};\n```\n\nIn addition to this, the public key has to be set up on the remote server side, so that user `sshified` can log in with this pivate key.\n\n## Prometheus configuration\n\nNow that we have a working http-to-ssh tunnel, we can finally tell prometheus to scrape the thing:\n\n```nix\nservices.prometheus.scrapeConfigs = [\n  {\n    job_name = \"ssh-tunnel\";\n    scheme = \"http\";\n    proxy_url = \"http://127.0.0.1:8888\";\n    static_configs = [\n      {\n        targets = [ \"1.2.3.4:9100\" ];\n      }\n    ];\n  }\n]\n```\nAfter checking the prometheus dashboard, we can verify that the target is alive! We have now successfully scraped metrics through SSH and our precious ports 80 and 443 stay unbothered.\n\n",
    "image": {
      "filename_disk": "f3e30685-d968-4ef2-a0a5-ada433312b26.jpg",
      "filename_download": "goltzius_prometheus.jpg"
    }
  },
  {
    "status": "published",
    "slug": "advent-of-code-2023-day-6",
    "date_created": "2023-12-06",
    "title": "Advent of Code 2023 Day 6",
    "tags": ["aoc", "programming"],
    "excerpt": "Wait For It",
    "content": "It's once again the best time of the year; [Advent of Code](https://adventofcode.com)! In this blog series I will be taking a look at all the puzzles of the year, and how I approached solving them. \n\nYou can find all of my solutions in my [git repo](https://git.joinemm.dev/advent-of-code/tree/master/2023).\n\n## Day 6: Wait For It\n\nToday we are taking a look at [Day 6](https://adventofcode.com/2023/day/6)\n\nWe need to find the amount of time to charge our boat to beat the best time. As soon as I read this puzzle, it was clear this was going to be a \"solve x\" math question.\n\nThe distance our boat travels can be expressed as a function of $$x$$, where $$x$$ is the amount of time we hold the button, and $$t$$ is the duration of the race.\n\n$$\n\\begin{align*}\nd &= x(t - x)\n\\end{align*}\n$$\n\nThis can then be rearranged to form a quadratic equation:\n\n$$\n\\begin{align*}\nd &= x(t - x) \\\\\n0 &= tx - x^2 - d \\\\\nax^2 - bx + c &= 0 \\\\\n\\end{align*}\n$$\n\nAs you might remember from high-school, quadratic equations can be solved with the quadratic formula:\n\n$$\n\\begin{align*}\n&x = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}\n\\end{align*}\n$$\n\nPlugging our values in, we get two points for $$x$$, which are the bounds of our winning area. Now, these are floats, so they must be `ceil()` and `floor()`:ed. There is one edge case where the bounds have no fractions, which would give us the answer to *match* the current record. The goal is to beat the record, so `+1` is added to fix this.\n\n## Python\n\nIn part 1 we solve the formula for each race and multiply the possibilities together to get our answer. For part 2, it's as simple as stripping out the whitespace and counting the formula once for the large numbers.\n\n```py\nfrom math import ceil, floor, sqrt\n\ndef quadratic_formula(a: int, b: int, c: int) -> tuple[int, int]:\n    return [(-b - sqrt(b**2 - 4 * a * c) * i) / (2 * a) for i in [1, -1]]\n\n\ndef part1(input: str):\n    times, distances = [\n        [int(x) for x in line.split(\":\", 1)[1].split()] for line in input.split(\"\\n\")\n    ]\n\n    total = 1\n    for time, distance in zip(times, distances):\n        x1, x2 = quadratic_formula(1, time, distance)\n        total *= ceil(x2) - floor(x1 + 1)\n\n    return total\n\n\ndef part2(input: str):\n    time, distance = [\n        int(\"\".join(line.split(\":\", 1)[1].split())) for line in input.split(\"\\n\")\n    ]\n\n    x1, x2 = quadratic_formula(1, time, distance)\n    return ceil(x2) - floor(x1 + 1)\n```",
    "image": {
      "filename_disk": "6c5cf6a9-f974-46ca-bcf2-6fbd93f27fc0.jpg",
      "filename_download": "6.jpg"
    }
  },
  {
    "status": "published",
    "slug": "advent-of-code-2023-day-1",
    "date_created": "2023-12-01",
    "title": "Advent of Code 2023 Day 1",
    "tags": ["aoc", "programming"],
    "excerpt": "Trebuchet?!",
    "content": "It's once again the best time of the year; [Advent of Code](https://adventofcode.com)! In this blog series I will be taking a look at all the puzzles of the year, and how I approached solving them. \n\nFor 2023 I chose to solve the puzzles in two languages; Python and Haskell. Python is my favorite language and the one I'm most familiar with, while haskell is a newer addition to my toolbox. In fact, I only started learning it yesterday! \n\nWith python I can focus on the puzzle at hand and try different things before landing on a solution that works. I can't exactly do that with haskell as it's more restricted and I have trouble understanding the syntax. So my approach is to then rewrite my python solution in a functional way using haskell.\n\nYou can find all of my solutions in my [git repo](https://git.joinemm.dev/advent-of-code/tree/master/2023).\n\n## Day 1: Trebuchet?!\n\nToday we are taking a look at [Day 1](https://adventofcode.com/2023/day/1)\n\nOur task is to find the first and last digit from each line of the input, combine these digits to a two-digit number, and sum them up. I approached this quite differently in both languages.\n\n## Python\n\nThis was relatively simple to solve, even if I was a little rusty. The last time I have done puzzles like this was last year's advent of code.\n\n### Part 1\n\n```py\ndef part1(input: str):\n    total = 0\n    for line in input.split(\"\\n\"):\n        val = \"\"\n        for i, step in [(0, 1), (len(line) - 1, -1)]:\n            while True:\n                try:\n                    val += str(int(line[i]))\n                    break\n                except ValueError:\n                    i += step\n\n        total += int(val)\n\n    return total\n```\n\nSo what's happening here? I'm running a while loop that finds the first digit from the string, before breaking and doing that same thing again but backwards (notice the `i` and `step` being the last index of the list and `-1` on the second pass of the for loop). Both digits are collected to a string which is then converted to an int and added to the total.\n\n### Part 2\n\n```py\ndef part2(input: str):\n    num_strings = {\n        \"one\": 1,\n        \"two\": 2,\n        \"three\": 3,\n        \"four\": 4,\n        \"five\": 5,\n        \"six\": 6,\n        \"seven\": 7,\n        \"eight\": 8,\n        \"nine\": 9,\n    }\n    total = 0\n    for line in input.split(\"\\n\"):\n        found = set()\n        for s, v in num_strings.items():\n            for i in [line.find(s), line.rfind(s)]:\n                if i > -1:\n                    found.add((i, v))\n\n        for i, step in [(0, 1), (len(line) - 1, -1)]:\n            while 0 <= i < len(line):\n                try:\n                    found.add((i, int(line[i])))\n                    break\n                except ValueError:\n                    i += step\n\n        found = sorted(found)\n        total += found[0][1] * 10 + found[-1][1]\n\n    return total\n```\n\nPart 2 adds a wrench into the mix by introducing digits that are spelled out. I'm reusing my digit finding code from part 1, but saving also the index they were found at, to be used later. For the spelled out numbers, I'm utilizing python's built in `.find()` and `.rfind()` to find the number closest to the start and end of the string, respectively. This process is done for each possible string in `num_strings` to find all the digits. In the end, the set of digits is sorted by the index, and it's first and last element combined to form our final value for the row. As before, these values are summed up to become our final answer.\n\n## Haskell\n\nOk so this one was not that easy. Haskell's syntax and types threw me off a loop but in the end I came up with a solution that compiles, and even gives me the right answer!\n\n### Part 1\n\n```hs\nsum [read [head nums, last nums] :: Int | nums <- [filter isDigit c | c <- lines input ] ]\n```\n\nIt's a single line! I am very proud of this thing. But what is happening?\n - Input is split into lines\n - Lines are filtered to only contain digits\n - The `head` and `last` of those digits are combined into a string\n - The resulting string (`Char` array) is read into an `Int`\n - Those `Int`s are summed up to become our answer\n\n### Part 2\n\nSorry for anyone who actually knows haskell...\n\n```hs\nsummer' :: String -> Int\nsummer' line = do\n  let nums = filter (>0) [reader' xs | xs <- tailor' line]\n  sum [read (show (head nums) ++ show( last nums)) :: Int ]\n\ndigiter' :: Char -> Int\ndigiter' c | isDigit c = read [c] :: Int\n           | otherwise = 0\n\nreader' :: String -> Int\nreader' s | \"one\" `isPrefixOf` s = 1\n          | \"two\" `isPrefixOf` s = 2\n          | \"three\" `isPrefixOf` s = 3\n          | \"four\" `isPrefixOf` s = 4\n          | \"five\" `isPrefixOf` s = 5\n          | \"six\" `isPrefixOf` s = 6\n          | \"seven\" `isPrefixOf` s = 7\n          | \"eight\" `isPrefixOf` s = 8\n          | \"nine\" `isPrefixOf` s = 9\n          | otherwise = digiter' (head s)\n\ntailor' :: String -> [String]\ntailor' []     = []\ntailor' (x:xs) = (x:xs) : tailor' xs\n\npart2' :: String -> Int\npart2' input = do\n  sum [ summer' line | line <- lines input ]\n```\n\nThe best way I found to solve this without for loops (haskell has no for loops!), was to take a line, create \"tails\" from it (each element being one head shorter than the last), check if each of those lines starts with a spelled out number or a digit, and transform the tail piece into the corresponding digit, reserving 0 for no digit. I then filter any 0s out of this list of digits, take the first and last elements and combine them into an Int. These numbers for every line are summed up, and there's your answer.\n",
    "image": {
      "filename_disk": "44cfe342-abd6-4d44-ae24-177004ca1248.jpg",
      "filename_download": "1.jpg"
    }
  },
  {
    "status": "archived",
    "slug": "recipe-italian-tomato-sauce",
    "date_created": "2023-08-05",
    "title": "Recipe: Pasta Bolognese",
    "tags": ["food", "recipe"],
    "excerpt": "Italian meat sauce for pasta with ground meat and tomatoes",
    "content": "I found this tomato meat sauce recipe somewhere on the internet, and with slight modifications, it has become one of my go-to weekend dinners. The addition of milk into the meat tenderizes it and cuts the acidity of the whole sauce, and the additional olive oil and grated garlic flavoring right before serving elevate the taste to another level.\n\nServes 4.\n\n## Ingredients \n\n- [ ] 1 onion\n- [ ] 3 garlic cloves\n- [ ] 400g ground meat half beef, half pork\n- [ ] ~1dl milk\n- [ ] 2 cans Mutti Polpa finely chopped tomatoes\n- [ ] 1 tablespoon tomato paste\n- [ ] Olive oil\n- [ ] Salt and pepper\n- [ ] Fresh basil\n- [ ] Spaghetti (bronze cut)\n- [ ] Parmesan / pecorino romano\n\n## Instructions\n\n![](https://cdn.joinemm.dev/assets/57a9a99c-5f06-4d74-9864-9d6cf55546a5)\n\nHeat some olive oil in a large skillet. On medium heat, fry the finely chopped onion until translucent.\n\nAdd the ground meat and break it into smaller pieces. Turn the heat to high and add the milk, stirring until it has evaporated.\n\nAdd the tomato paste and let it brown slightly. Add the canned tomatoes, clean the cans with a little water and add that water in as well. Add 2 cloves of grated garlic (leaving 1 for later), a lot of basil leaves and some salt & pepper to taste.\n\nBring the sauce to a boil, turn the heat down to low, cover with a lid leaving it a bit ajar and simmer for around 20 minutes, stirring occasionally. \n\nAfter 20 minutes remove the lid and continue simmering for 10 minutes, until the sauce thickens slightly. This is a good time to start cooking your pasta as it usually takes around 10 minutes to 'al dente'.\n\nFew minutes before serving, add the remaining grated garlic, drizzle in some olive oil, add more fresh basil and stir, letting the flavors get to know each other.\n\nPlate up, topping with shredded fresh basil, a drizzle of olive oil and grated parmesan cheese. Serve with a glass of red wine.\n\nEnjoy!",
    "image": {
      "filename_disk": "c3223f9b-1aab-4e20-90ce-e9780501f903.jpg",
      "filename_download": "PSX_20230805_175211.jpg"
    }
  },
  {
    "status": "published",
    "slug": "csgo-linux-setup",
    "date_created": "2023-06-12",
    "title": "Optimize CS:GO for Arch Linux and Vulkan",
    "tags": ["gaming", "linux"],
    "excerpt": "Get the best performance out of Counter-Strike Global Offensive on your Linux pc.",
    "content": "While csgo runs just fine out of the box on Linux thanks to Valve providing a native Linux build, more competitive players could be left disappointed with its performance and various graphical bugs. In this article I go through every tweak and change I made to optimize my csgo experience on Arch Linux running DWM window manager, and an AMD graphics card.\n\nThe finished result runs even better and smoother than the Windows counterpart, and with less input lag and latency.\n\n## GameMode\n\n> GameMode is a daemon/lib combo for Linux that allows games to request a set of optimisations be temporarily applied to the host OS and/or a game process.\n\nRunning csgo with [GameMode](https://github.com/FeralInteractive/gamemode) might be the easiest upgrade to the game's performance you can make. Simply add this to your csgo launch options:\n\n```\ngamemoderun %command%\n```\n\n## Vulkan\n\nCSGO on Linux runs on OpenGL by default. This works on all platforms, but results in poor performance and numerous graphical bugs such as:\n\n- [Textures on walls flickering](https://github.com/ValveSoftware/csgo-osx-linux/issues/3168)\n- [All glove skins rendering fully black](https://github.com/ValveSoftware/csgo-osx-linux/issues/2102)\n\nAs someone who likes csgo skins, the glove issue was enough to push me away from OpenGL.\n\nThe solution? Use Vulkan! Simply add `-vulkan` to your launch options and the game now runs on the Vulkan API.\n\nUnfortunately, just doing this results in unplayable levels of stuttering as the game compiles shaders during gameplay. This _might_ go away after playing for some time and running all around every map but I found that no matter how long I played there would still be stutters, especially when people are shooting or peeking me (and if you play cs, you know this is the _worst_ time to experience stuttering)\n\n### Drivers\n\nAs per the vulkan page on [Arch Wiki](https://wiki.archlinux.org/title/Vulkan), There are three different implementations of the Vulkan driver for AMD:\n\n- `vulkan-radeon` - RADV (part of Mesa project)\n- `amdvlk` - AMDVLK Open (maintained by AMD)\n- `vulkan-amdgpu-proAUR` - AMDVLK Closed (maintained by AMD)\n\nWhat we need is the RADV driver. You can actually have all of these installed at the same time and choose which one to use on per application basis by using `amd-vulkan-prefixes` (from the AUR). Specify CSGO to use the RADV driver by prepending your launch options with `vk_radv`\n\n```\nvk_radv gamemoderun %command% -vulkan\n```\n\n### Fixing the stuttering\n\nThe csgo Linux build ships with an old version of dxvk-native (1.9.1), but what if I told you, you can actually update this binary in the game files to a newer version and the game still runs fine?\n\n> \"But why?\" you ask.\n\nBecause DXVK 2.0 comes with bunch of performance improvements, the most important of which is **async shader compilation**. This is the secret sauce to fixing our stuttering game.\n\n**Step 1.** Download the newest release of [dxvk-native-2.x-steamrt-sniper.tar.gz](https://github.com/doitsujin/dxvk/releases). At the time of this writing the newest version is 2.2.\n\n**Step 2.** Extract the tar archive you downloaded and copy the 64 bit binary into your csgo folder, replacing the path with your own steam library location:\n\n```sh\ntar -xf dxvk-native-2.2-steamrt-sniper.tar.gz --one-top-level\ncd lib\ncp libdxvk_d3d9.so 'path/to/steamlibrary/steamapps/common/Counter-Strike Global Offensive/bin/linux64/'\n```\n\n**Step 3.** Enable the async shader compilation with `DXVK_ASYNC=1` env variable. This can be easily added to the beginning of your launch options. While we're here we can customize the DXVK hud. I've set mine to just an FPS counter, but you can find more options in the [README](https://github.com/doitsujin/dxvk#hud). There are some interesting options available such as `frametimes` and `compiler` you can play with.\n\n```\nDXVK_ASYNC=1 DXVK_HUD=fps vk_radv gamemoderun %command% -vulkan\n```\n\n## Compositor latency\n\nIf you run a compositor like most people (picom/compton) then you will have always-on VSYNC. As we all know, vsync introduces input lag. What can you do? Well you could just kill your compositor every time you play with a little `killall picom` and get it back up when you're done, but that's lame and a lot of manual work.\n\nThankfully, picom includes a very nice config option to disable compositing when there is only one fullscreen application on the screen. Just add this into your `.config/picom.conf`:\n\n```\nunredir-if-possible = true\n```\n\nThis works for the most part, but if you get a notification that draws over the game window, it is no longer considered fullscreen and your vsync will be turned back on. To remedy this, we can set the wintypes like this:\n\n```\nwintypes:\n{\n  notification = { redir-ignore = true; }\n  notify = { redir-ignore = true; }\n};\n```\n\n## CSGO lauch options\n\nThese are the csgo launch options I like to use that are not Linux specific, but I'll list them here for completeness' sake.\n\n- `-novid` Removes the intro video\n- `-tickrate 128` Self explanatory. Enables 128 tick when available.\n- `-fullscreen1` Force real fullscreen. Reduces latency.\n- `-nojoy` Disable controllers.\n\nFinally, here is my full launch options string in all its glory:\n\n```\nDXVK_ASYNC=1 DXVK_HUD=fps vk_radv gamemoderun %command% -novid -tickrate 128 -fullscreen1 -vulkan -nojoy\n```",
    "image": {
      "filename_disk": "3f535af2-246e-42d8-a3d7-636eca4825ae.jpg",
      "filename_download": "csgo.jpg"
    }
  },
  {
    "status": "published",
    "slug": "anti-aliasing",
    "date_created": "2023-03-27",
    "title": "Common anti-aliasing methods",
    "tags": ["gaming", "graphics"],
    "excerpt": "Anti-Aliasing in video games and rendering applications set out to solve a problem inherent with our displays: pixels.",
    "content": "Anti-Aliasing in video games and rendering applications set out to solve a problem inherent with our displays: **pixels**. The very things that compose the images we see on our screens are simultaneously what cause a lot of issues and break immersion. Pixels are aligned in perfectly straight lines, which means that unless you have equally perfectly straight vertical or horizontal lines being displayed on your screen, you will encounter a form of artifacting known as aliasing. In layman's terms, these are also referred to as “stairstepping” or “jaggies”.\n\nA very simple way of visualizing it is like trying to make a smooth 45° line with Minecraft blocks. On the surface, you can't, because each block is a perfect cube (or a square, if viewed head-on), and since they don't line up horizontally or vertically, but diagonally, you get this “stairstepping” effect. Fortunately, several different methods of combatting this effect have been developed over the years. Generally speaking, these can be divided into two camps, the “supersampling” forms and the “post-processing” forms, the latter of which also has another “temporal” subcategory.\n\n## SSAA\n\nStands for **Supersampling Anti-Aliasing**. This method essentially renders the frame at a higher resolution internally in order to gather more data for the pixels, which it then uses to smooth these out. More specifically, it samples these pixels multiple times to calculate an average for said pixel, which is what it will then use for the actual rendered frame. SSAA is essentially a more intensive but also more extensive method than MSAA, although both operate using the same principle, just with differing implementation.\n\nYou can imagine this as watching a 4K video on a 1080p screen, the original 4K frame is downscaled to your 1080p viewport, however since the 4K frame has far more pixels, it has far more data to work with when trying to smooth out aliasing. In that sense, SSAA is both the simplest and the most intensive form of anti-aliasing.\n\n## MSAA\n\nStands for **Multi-Sampling Anti-Aliasing**. Technically speaking, it is a form of SSAA (supersampling). With MSAA, instead of rendering the entire frame at a higher resolution and then downscaling to the viewport, it only renders certain parts of the frame at a “higher resolution”. Strictly speaking, it doesn't do so at a higher resolution, but rather it samples and re-renders certain pixels several times to calculate the pixels along an object edge for example. The functionality of MSAA can be further increased by technologies such es edge detection, which can reduce the computational load incurred by MSAA by only applying it to relevant sections, which are almost always edges of objects.\n\n## FXAA\n\nStands for **Fast Approximate Anti-Aliasing**. Developed by an Nvidia engineer called Timothy Lottes; however the technology is not exclusive to Nvidia cards. FXAA uses an algorithm which requires a rendered frame and its luminance data. You can think of luminance data almost like a heatmap of which parts of a frame are dark, and which ones are light. Using the frame and the data, it then searches for high contrast edges, where the frame goes from light to dark back to light, such as a powerline in the sky. It then focuses on that part of the frame and calculates a factor to essentially blend the pixels along the edge to reduce their perceived jaggedness.\n\n## TAA\n\nStands For **Temporal Anti-Aliasing**. Does what it says on the box; it uses temporal information in order to eliminate aliasing. This temporal information usually consists of the preceding frame and its motion vectors. Furthermore, TAA also uses something called subpixel jittering, which, put simply, just means that the frame is slightly shuffled around, resulting in pixels being sampled in different locations. Using that information, the GPU then blends pixels along edges in order to smooth these out. Similar to FXAA, it is also a form of post processing anti-aliasing, but it's the additional temporal information being incorporated that sets it apart.\n\n## SMAA\n\nStands for **Subpixel Morphological Anti-Aliasing**. This is one of the newer technologies, and incorporates a variety of tech, including edge detection (like MSAA), along with pattern, gradient and depth recognition in order to more accurately apply anti-aliasing to relevant areas. It includes parts of the supersampling, the post-processing and the temporal approach. Due to this, it is relatively intensive, roughly on par with MSAA, while in practice producing very similar results. As such, SMAA hasn't found very widespread adoption in the past 10+ years since its inception, as developers for the most part simply stick to the tried and tested MSAA, which has been around for much longer.\n\n## DLAA\n\nStands for **Deep Learning Anti-Aliasing**. Like DLSS, this leverages machine learning, except rather than training algorithms for upscaling, it uses algorithms trained for anti-aliasing. Most of the heavy lifting was done on Nvidia supercomputers, giving birth to an algorithm which is very good at detecting edges, corners, high contrast areas, identifying which of these need anti-aliasing, and then applying it. Unlike for example MSAA, DLAA only samples each pixel once, but similar to TAA, it integrates motion vectors, and uses the available data to compare against 16K reference images, just like DLSS would do. As such, DLAA is only available for Nvidia GPUs, specifically those with tensor cores, so the RTX 2000, 3000 and 4000 series.\n\n## Conclusion\n\nThis list only covered the 6 most common types of anti-aliasing techniques found in games today. There are certainly many more methods, although a lot of these are either Nvidia or AMD exclusive, are often simply tweaks to the sampling methods of MSAA, and have for the most part fallen into disuse. Booting up an older game, it's very possible you'll find settings for CSAA, QSAA or EQAA, which are all proprietary, tweaked version of MSAA.\n\n> \"the world does NOT need another goober like me with a blog that nobody reads\"  \n> — muggs",
    "image": {
      "filename_disk": "176c417a-9515-4f09-b85b-96817cb3236c.avif",
      "filename_download": "9ef73-16510051165239-1920.avif"
    }
  },
  {
    "status": "published",
    "slug": "minecraft-server-centos",
    "date_created": "2022-09-11",
    "title": "Setting up a Minecraft server with mods on CentOS",
    "tags": ["gaming", "linux", "server"],
    "excerpt": "The best way to set up your next Minecraft server",
    "content": "Always wanted to host your own Minecraft server but don't know how? In this tutorial, we'll go through the steps necessary to install and configure Minecraft Server on a CentOS 9 headless server. We're going to use systemd to run the Minecraft server and the mcrcon utility for server maintenance. We'll also set up automated server backups using a cron job.\n\n## Prerequisites\n\nFirst you obviously need a CentOS server. My preferred provider is [Hetzner](https://hetzner.joinemm.dev) due to them being based in Europe and offering competitive prices. For my small server I chose a 3 vcore 4gb Ram machine.\n\nWe'll also need [EPEL](https://docs.fedoraproject.org/en-US/epel/) to install the latest version of java on CentOS.\n\n```sh\ndnf config-manager --set-enabled crb\ndnf install epel-release epel-next-release\n```\n\nSince the Minecraft Server doesn't need a graphical user interface, we can install the headless version of the openjdk.\n\n```sh\nyum install java-latest-openjdk-headless\n```\n\nFor editing the config files I like to use vim, but you can substitute that with your favourite text editor such as nano.\n\n```sh\nyum install git neovim\n```\n\n### Create the minecraft user\n\nWe don't want to run the minecraft server as root for security reasons. Let's create a new user and group `minecraft` with home directory `/opt/minecraft`:\n\n```sh\nuseradd -r -m -U -d /opt/minecraft -s /bin/bash minecraft\n```\n\nWe are not going to set a password for this user. This is good security practice because this user will not be able to login via SSH. To change to the minecraft user you'll need to be logged in to the server as root or user with sudo privileges.\n\nSwitch to the minecraft user:\n\n```sh\nsu - minecraft\n```\n\nFirst we're going to make some folders. Make sure you're in the home folder (`/opt/minecraft` in our case).\n\n```sh\nmkdir {server,scripts,backups}\n```\n\n## Download the server.jar\n\nVanilla minecraft versions can be found here https://mcversions.net/. Browse to your preferred version and right click the `Download Server Jar` button. Choose to copy the link.\n\nFor this tutorial I'm going to use Minecraft 1.18.2\n\n```sh\ncd server\nwget https://launcher.mojang.com/v1/objects/c8f83c5655308435b3dcf03c06d9fe8740a77469/server.jar\n```\n\nIf you want to run a modded server, you're going to need the Forge version of the server. Find your preferred version of Forge from https://files.minecraftforge.net/net/minecraftforge/forge/ and copy the download link.\n\nRemove the leading `https://adfoc.us/serve/sitelinks/?id=271228&url=` ad tracker from the link.\n\nFor this tutorial I'm going to use Forge 1.18.2\n\n```sh\nwget https://maven.minecraftforge.net/net/minecraftforge/forge/1.18.2-40.1.80/forge-1.18.2-40.1.80-installer.jar\njava -jar forge-1.18.2-40.1.80-installer.jar --installServer\n```\n\n## Configure the server\n\nFirst try starting the server. Modify the Xmx and Xms flags according to your server resources. The Xmx flag defines the maximum memory allocation pool for a Java virtual machine (JVM), while Xms defines the initial memory allocation pool.\n\nIf using forge, the memory configuration is done by editing the `user_jvm_args.txt` file.\n\n```sh\n# vanilla\njava -Xmx4116M -Xms1024M -jar server.jar nogui\n# forge\n./run.sh nogui\n```\n\nYou will not get far before the server asks you to accept the EULA. Shut it down and go edit `eula.txt`\n\nchange `eula=false` to `eula=true`.\n\nNext we're going to edit the `server.properties` file. Locate and edit the following lines. This is for mcrcon to work properly. You should also change the password to something stronger. While you're here, you can set whatever [server properties](https://minecraft.fandom.com/wiki/Server.properties) you would like your server to have.\n\n```sh\nrcon.password=amazing-password\nenable-rcon=true\n```\n\n## Running through systemd\n\nFirst switch back to your root user by typing `exit`.\n\nCreate a new service file:\n\n```sh\nnvim /etc/systemd/system/minecraft.service\n```\n\nPaste this configuration in, changing the mcrcon password to whatever you set it to be earlier:\n\n```ini\n[Unit]\nDescription=Minecraft Server\nAfter=network.target\n\n[Service]\nUser=minecraft\nNice=1\nKillMode=none\nSuccessExitStatus=0 1\nProtectHome=true\nProtectSystem=full\nPrivateDevices=true\nNoNewPrivileges=true\nWorkingDirectory=/opt/minecraft/server\nExecStart=/usr/bin/java -Xmx4116M -Xms1024M -jar server.jar nogui\nExecStop=/opt/minecraft/tools/mcrcon/mcrcon -H 127.0.0.1 -P 25575 -p awesome-password stop\n\n[Install]\nWantedBy=multi-user.target\n```\n\nEdit the `ExecStart` to your preferred memory configuration. If running forge, change it to `/opt/minecraft/server/run.sh nogui`\n\nStart the service and enable it to start on boot.\n\n```sh\nsystemctl daemon-reload\nsystemctl start minecraft\nsystemctl enable minecraft\n```\n\nYou can see the status of your server by typing:\n\n```sh\nsystemctl status minecraft\n```\n\nOr if you want to follow the logs:\n\n```sh\njournalctl -fu minecraft\n```\n\n## mcrcon\n\n[mcrcon](https://github.com/Tiiffi/mcrcon) is console based Minecraft rcon client for remote administration and server maintenance scripts. We're going to install it system wide.\n\nInstall the building tools:\n\n```sh\nyum group install \"Development Tools\"\n```\n\nCompile and install mcrcon:\n\n```sh\ngit clone https://github.com/Tiiffi/mcrcon.git\ncd mcrcon\nmake\nsudo make install\n```\n\nTest that everything works. This should output the mcrcon help.\n\n```sh\nmcrcon -h\n```\n\n### Configuring daily backups\n\nStart by switching to the minecraft user:\n\n```sh\nsu - minecraft\n```\n\nCreate a backup script in the scripts folder we created.\n\n```sh\nnvim ~/scripts/backup.sh\n```\n\nPaste the following configuration, and change the rcon password to whatever you set it to earlier:\n\n```sh\n#!/bin/bash\n\nfunction rcon {\n  /opt/minecraft/tools/mcrcon/mcrcon -H 127.0.0.1 -P 25575 -p awesome-password \"$1\"\n}\n\nrcon \"save-off\"\nrcon \"save-all\"\ntar -cvpzf /opt/minecraft/backups/server-$(date +%F-%H-%M).tar.gz /opt/minecraft/server\nrcon \"save-on\"\n\n## Delete older backups\nfind /opt/minecraft/backups/ -type f -mtime +7 -name '*.gz' -delete\n```\n\nMake the script executable:\n\n```sh\nchmod +x ~/scripts/backup.sh\n```\n\nEdit your crontab:\n\n```sh\ncrontab -e\n```\n\nPaste in the following. We'll run the backup every day at 6am.\n\n```sh\n0 6 * * * /opt/minecraft/tools/backup.sh\n```\n\n### Using mcrcon manually\n\nTo issue commands to the minecraft console:\n\n```sh\nmcrcon -H 127.0.0.1 -P 25575 -p awesome-password -t\n```\n\nYou should see the following:\n\n```sh\nLogged in. Type \"Q\" to quit!\n>\n```\n\nInstead of typing this manually, you should create an alias:\n\n```sh\nalias mc=\"mcrcon -H 127.0.0.1 -P 25575 -p awesome-password -t\"\n```\n\nTo make this persist, add it to the end of your `.bashrc`.\n\n## Adding mods and resource packs\n\nIf you want to add mods to your forge server, you can download the mod `.jar` files and add them to the `~/server/mods` folder.\n\nIf you want your players to be prompted for a resource pack, add the direct download link to `server.properties`\n\n```ini\nrequire_resource_pack=false\nresource_pack=link-to-zip-file\nresource_pack_prompt={\"text\": \"get this pls\", \"color\": \"gold\"}\n```\n\n## Credits\n\nThanks to Linuxize for [this](https://linuxize.com/post/how-to-install-minecraft-server-on-centos-7/) tutorial which I used as a basis for this article.",
    "image": {
      "filename_disk": "a2ecbff4-3b64-403c-9aa3-5d07a508cb19.jpg",
      "filename_download": "9bbef21ffd9fff6bbf2b997778f5023c.jpg"
    }
  },
  {
    "status": "archived",
    "slug": "TEST",
    "date_created": "2022-01-01",
    "title": "Test document for markdown syntax",
    "tags": [],
    "excerpt": "Verifies that all markdown elements render properly. Not meant for public consumption.",
    "content": "## math is cool\n\n$f(x)=\\frac{P(x)}{Q(x)}$ and $f(x)=\\textstyle\\frac{P(x)}{Q(x)}$\n\ninnit\n\n![jinsoul eating pizza](https://cdn.joinemm.dev/assets/5f2784a1-59bb-4def-92ed-1df5b4790419)\n\n## Overview\n\n### Philosophy\n\nMarkdown is intended to be as easy-to-read and easy-to-write as is feasible.\n\nReadability, however, is emphasized above all else. A Markdown-formatted\ndocument should be publishable as-is, as plain text, without looking\nlike it's been marked up with tags or formatting instructions. While\nMarkdown's syntax has been influenced by several existing text-to-HTML\nfilters -- including [Setext](http://docutils.sourceforge.net/mirror/setext.html), [atx](http://www.aaronsw.com/2002/atx/), [Textile](http://textism.com/tools/textile/), [reStructuredText](http://docutils.sourceforge.net/rst.html),\n[Grutatext](http://www.triptico.com/software/grutatxt.html), and [EtText](http://ettext.taint.org/doc/) -- the single biggest source of\ninspiration for Markdown's syntax is the format of plain text email.\n\n## Block Elements\n\n### Paragraphs and Line Breaks\n\nA paragraph is simply one or more consecutive lines of text, separated\nby one or more blank lines. (A blank line is any line that looks like a\nblank line -- a line containing nothing but spaces or tabs is considered\nblank.) Normal paragraphs should not be indented with spaces or tabs.\n\nThe implication of the \"one or more consecutive lines of text\" rule is\nthat Markdown supports \"hard-wrapped\" text paragraphs. This differs\nsignificantly from most other text-to-HTML formatters (including Movable\nType's \"Convert Line Breaks\" option) which translate every line break\ncharacter in a paragraph into a `<br />` tag.\n\nWhen you _do_ want to insert a `<br />` break tag using Markdown, you\nend a line with two or more spaces, then type return.\n\n### Headers\n\nMarkdown supports two styles of headers, [Setext] [1] and [atx] [2].\n\nOptionally, you may \"close\" atx-style headers. This is purely\ncosmetic -- you can use this if you think it looks better. The\nclosing hashes don't even need to match the number of hashes\nused to open the header. (The number of opening hashes\ndetermines the header level.)\n\n### Blockquotes\n\nMarkdown uses email-style `>` characters for blockquoting. If you're\nfamiliar with quoting passages of text in an email message, then you\nknow how to create a blockquote in Markdown. It looks best if you hard\nwrap the text and put a `>` before every line:\n\n> This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,\n> consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.\n> Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\n>\n> Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse\n> id sem consectetuer libero luctus adipiscing.\n\nMarkdown allows you to be lazy and only put the `>` before the first\nline of a hard-wrapped paragraph:\n\n> This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,\n> consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.\n> Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\n\n> Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse\n> id sem consectetuer libero luctus adipiscing.\n\nBlockquotes can be nested (i.e. a blockquote-in-a-blockquote) by\nadding additional levels of `>`:\n\n> This is the first level of quoting.\n>\n> > This is nested blockquote.\n>\n> Back to the first level.\n\nBlockquotes can contain other Markdown elements, including headers, lists,\nand code blocks:\n\n> ## This is a header.\n>\n> 1.  This is the first list item.\n> 2.  This is the second list item.\n>\n> Here's some example code:\n>\n>     return shell_exec(\"echo $input | $markdown_script\");\n\nAny decent text editor should make email-style quoting easy. For\nexample, with BBEdit, you can make a selection and choose Increase\nQuote Level from the Text menu.\n\n### Lists\n\nMarkdown supports ordered (numbered) and unordered (bulleted) lists.\n\nUnordered lists use asterisks, pluses, and hyphens -- interchangably\n-- as list markers:\n\n- Red\n- Green\n- Blue\n\nis equivalent to:\n\n- Red\n- Green\n- Blue\n\nand:\n\n- Red\n- Green\n- Blue\n\nOrdered lists use numbers followed by periods:\n\n1.  Bird\n2.  McHale\n3.  Parish\n\nIt's important to note that the actual numbers you use to mark the\nlist have no effect on the HTML output Markdown produces. The HTML\nMarkdown produces from the above list is:\n\nIf you instead wrote the list in Markdown like this:\n\n1.  Bird\n1.  McHale\n1.  Parish\n\nor even:\n\n3. Bird\n1. McHale\n1. Parish\n\nyou'd get the exact same HTML output. The point is, if you want to,\nyou can use ordinal numbers in your ordered Markdown lists, so that\nthe numbers in your source match the numbers in your published HTML.\nBut if you want to be lazy, you don't have to.\n\nTo make lists look nice, you can wrap items with hanging indents:\n\n- Lorem ipsum dolor sit amet, consectetuer adipiscing elit.\n  Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,\n  viverra nec, fringilla in, laoreet vitae, risus.\n- Donec sit amet nisl. Aliquam semper ipsum sit amet velit.\n  Suspendisse id sem consectetuer libero luctus adipiscing.\n\nBut if you want to be lazy, you don't have to:\n\n- Lorem ipsum dolor sit amet, consectetuer adipiscing elit.\n  Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,\n  viverra nec, fringilla in, laoreet vitae, risus.\n- Donec sit amet nisl. Aliquam semper ipsum sit amet velit.\n  Suspendisse id sem consectetuer libero luctus adipiscing.\n\nList items may consist of multiple paragraphs. Each subsequent\nparagraph in a list item must be indented by either 4 spaces\nor one tab:\n\n1.  This is a list item with two paragraphs. Lorem ipsum dolor\n    sit amet, consectetuer adipiscing elit. Aliquam hendrerit\n    mi posuere lectus.\n\n    Vestibulum enim wisi, viverra nec, fringilla in, laoreet\n    vitae, risus. Donec sit amet nisl. Aliquam semper ipsum\n    sit amet velit.\n\n2.  Suspendisse id sem consectetuer libero luctus adipiscing.\n\nIt looks nice if you indent every line of the subsequent\nparagraphs, but here again, Markdown will allow you to be\nlazy:\n\n- This is a list item with two paragraphs.\n\n      This is the second paragraph in the list item. You're\n\n  only required to indent the first line. Lorem ipsum dolor\n  sit amet, consectetuer adipiscing elit.\n\n- Another item in the same list.\n\nTo put a blockquote within a list item, the blockquote's `>`\ndelimiters need to be indented:\n\n- A list item with a blockquote:\n\n  > This is a blockquote\n  > inside a list item.\n\nTo put a code block within a list item, the code block needs\nto be indented _twice_ -- 8 spaces or two tabs:\n\n- A list item with a code block:\n\n      code goes here\n\n### Code Blocks\n\nPre-formatted code blocks are used for writing about programming or\nmarkup source code. Rather than forming normal paragraphs, the lines\nof a code block are interpreted literally. Markdown wraps a code block\nin both `<pre>` and `<code>` tags.\n\nTo produce a code block in Markdown, simply indent every line of the\nblock by at least 4 spaces or 1 tab.\n\nThis is a normal paragraph:\n\n    This is a code block.\n\nHere is an example of AppleScript:\n\n    tell application \"Foo\"\n        beep\n    end tell\n\nA code block continues until it reaches a line that is not indented\n(or the end of the article).\n\nWithin a code block, ampersands (`&`) and angle brackets (`<` and `>`)\nare automatically converted into HTML entities. This makes it very\neasy to include example HTML source code using Markdown -- just paste\nit and indent it, and Markdown will handle the hassle of encoding the\nampersands and angle brackets. For example, this:\n\nRegular Markdown syntax is not processed within code blocks. E.g.,\nasterisks are just literal asterisks within a code block. This means\nit's also easy to use Markdown to write about Markdown's own syntax.\n\n```\ntell application \"Foo\"\n    beep\nend tell\n```\n\n## Span Elements\n\n### Links\n\nMarkdown supports two style of links: _inline_ and _reference_.\n\nIn both styles, the link text is delimited by [square brackets].\n\nTo create an inline link, use a set of regular parentheses immediately\nafter the link text's closing square bracket. Inside the parentheses,\nput the URL where you want the link to point, along with an _optional_\ntitle for the link, surrounded in quotes. For example:\n\nThis is [an example](http://example.com/) inline link.\n\n[This link](http://example.net/) has no title attribute.\n\n### Emphasis\n\nMarkdown treats asterisks (`*`) and underscores (`_`) as indicators of\nemphasis. Text wrapped with one `*` or `_` will be wrapped with an\nHTML `<em>` tag; double `*`'s or `_`'s will be wrapped with an HTML\n`<strong>` tag. E.g., this input:\n\n_single asterisks_\n\n_single underscores_\n\n**double asterisks**\n\n**double underscores**\n\n### Code\n\nTo indicate a span of code, wrap it with backtick quotes (`` ` ``).\nUnlike a pre-formatted code block, a code span indicates code within a\nnormal paragraph. For example:\n\nUse the `printf()` function.",
    "image": {
      "filename_disk": "",
      "filename_download": ""
    }
  }
]
